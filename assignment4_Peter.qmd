---
title: "Assignment 4"
subtitle: "Due at 11:59pm on November 7."
author: Bozhou(Peter) Tan
format: 
  html:
    embed-resources: true
editor: source
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE,
                      message=FALSE, warning=FALSE)
```

GitHub: <https://github.com/petertbz/Assignment-4--727.git>

This is an individual assignment. Turn in this assignment as an HTML or PDF file to ELMS. Make sure to include the R Markdown or Quarto file that was used to generate it. Include the GitHub link for the repository containing these files.

```{r}
#| include: false 
library(tidyverse)
library(DBI)
library(dbplyr)
library(bigrquery)
library(knitr)
```

In this notebook we will use Google BigQuery, "Google's fully managed, petabyte scale, low cost analytics data warehouse". Some instruction on how to connect to Google BigQuery can be found here: <https://db.rstudio.com/databases/big-query/>.

You will need to set up a Google account with a project to be able to use this service. We will be using a public dataset that comes with 1 TB/mo of free processing on Google BigQuery. As long as you do not repeat the work in this notebook constantly, you should be fine with just the free tier.

Go to <https://console.cloud.google.com> and make sure you are logged in a non-university Google account. **This may not work on a university G Suite account because of restrictions on those accounts.** Create a new project by navigating to the dropdown menu at the top (it might say "Select a project") and selecting "New Project" in the window that pops up. Name it something useful.

After you have initialized a project, paste your project ID into the following chunk.

```{r}
project <- "assignment4-727"
```

We will connect to a public database, the Chicago crime database, which has data on crime in Chicago.

```{r}
con <- dbConnect(
  bigrquery::bigquery(),
  project = "bigquery-public-data",
  dataset = "chicago_crime",
  billing = project
)
con
```

We can look at the available tables in this database using `dbListTables`.

**Note**: When you run this code, you will be sent to a browser and have to give Google permissions to Tidyverse API Packages. **Make sure you select all to give access or else your code will not run.**

```{r}
dbListTables(con)
```

Information on the \`crime\` table can be found here:

<https://cloud.google.com/bigquery/public-data/chicago-crime-data>

Write a first query that counts the number of rows of the \`crime\` table in the year 2016. Use code chunks with {sql connection = con} in order to write SQL code within the document.

```{sql connection = con}
SELECT COUNT(*) AS rownumber
FROM crime
WHERE year = 2016;
```

Next, count the number of arrests grouped by `primary_type` in 2016. Note that is a somewhat similar task as above, with some adjustments on which rows should be considered. Sort the results, i.e. list the number of arrests in a descending order.

```{sql connection = con, max.print = -1}
SELECT primary_type, COUNT(*) AS num_arrests
FROM crime
WHERE year = 2016 AND arrest = true
GROUP BY primary_type
ORDER BY num_arrests DESC;
```

We can also use the `date` for grouping. Count the number of arrests grouped by hour of the day in 2016. You can extract the latter information from `date` via `EXTRACT(HOUR FROM date)`. Which time of the day is associated with the most arrests?

```{sql connection = con, max.print = -1}
SELECT EXTRACT(HOUR FROM date) AS hour_of_day, COUNT(*) AS num_arrests
FROM crime
WHERE year = 2016 AND arrest = true
GROUP BY hour_of_day
ORDER BY hour_of_day ASC;
```

Focus only on `HOMICIDE` and count the number of arrests for this incident type, grouped by year. List the results in descending order.

```{sql connection = con, max.print = -1}
SELECT year, COUNT(*) AS num_homicide
From crime
WHERE primary_type = "HOMICIDE"
GROUP BY year
ORDER BY num_homicide DESC;
```

Find out which districts have the highest numbers of arrests in 2015 and 2016. That is, count the number of arrests in 2015 and 2016, grouped by year and district. List the results in descending order.

```{sql connection = con, max.print = -1}
SELECT district, year, COUNT(*) AS num_arrest
FROM crime
WHERE year = 2015 OR year = 2016
GROUP BY year, district
ORDER BY num_arrest DESC;
```

Lets switch to writing queries from within R via the `DBI` package. Create a query object that counts the number of arrests grouped by `primary_type` of district 11 in year 2016. The results should be displayed in descending order.

```{r}
query = "SELECT primary_type, COUNT(arrest) AS num_arrest 
  FROM crime
  WHERE district = 11 AND year = 2016 AND arrest = true
  GROUP BY primary_type 
  ORDER BY num_arrest DESC"
```

Execute the query.

```{r}
kable(dbGetQuery(con, query))
```

Try to write the very same query, now using the `dbplyr` package. For this, you need to first map the `crime` table to a tibble object in R.

```{r}
crime_query = "SELECT * FROM crime" 
crime = tbl(con, sql(crime_query))
```

Again, count the number of arrests grouped by `primary_type` of district 11 in year 2016, now using `dplyr` syntax.

```{r}
crime %>% filter(district == 11 & year == 2016 & arrest == TRUE) %>% 
  group_by(primary_type) %>% 
  summarise(num_arrest = n()) %>% 
  arrange(desc(num_arrest)) %>% 
  kable()
```

Count the number of arrests grouped by `primary_type` and `year`, still only for district 11. Arrange the result by `year`.

```{r}
crime %>% filter(district == 11 & arrest == TRUE) %>% 
  group_by(primary_type, year) %>% 
  summarise(num_arrest = n()) %>% 
  arrange(year) %>% 
  kable()
```

Assign the results of the query above to a local R object.

```{r}
query = crime %>% filter(district == 11 & arrest == TRUE) %>% 
  group_by(primary_type, year) %>% 
  summarise(num_arrest = n()) %>% 
  arrange(year, num_arrest)
```

Confirm that you pulled the data to the local environment by displaying the first ten rows of the saved data set.

```{r}
kable(head(query, 10))
```

Close the connection.

```{r}
dbDisconnect(con)
```
